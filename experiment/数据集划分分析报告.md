# 数据集划分分析报告

## 执行时间
2024年分析

## 问题描述

数据集中定义了训练集和验证集的划分，位于 `/workspace/data` 目录下：
- `train_val_list.txt`: 包含训练/验证集的文件名列表（86,523 个样本）
- `test_list.txt`: 包含测试集的文件名列表（25,595 个样本）

## 当前代码实现分析

### 1. 训练脚本中的划分方式 (`scripts/train_model.py`)

**位置**: 第 165-191 行

```python
#cut out training sets
train_datas = []
test_datas = []
for i, dataset in enumerate(datas):
    # give patientid if not exist
    if "patientid" not in dataset.csv:
        dataset.csv["patientid"] = ["{}-{}".format(dataset.__class__.__name__, i) for i in range(len(dataset))]
        
    gss = sklearn.model_selection.GroupShuffleSplit(train_size=0.8,test_size=0.2, random_state=cfg.seed)
    
    train_inds, test_inds = next(gss.split(X=range(len(dataset)), groups=dataset.csv.patientid))
    train_dataset = xrv.datasets.SubsetDataset(dataset, train_inds)
    test_dataset = xrv.datasets.SubsetDataset(dataset, test_inds)
    
    train_datas.append(train_dataset)
    test_datas.append(test_dataset)
```

**问题**: 
- ❌ **未使用预定义的划分文件**
- ❌ 使用 `GroupShuffleSplit` 进行**随机划分**（80% 训练，20% 测试）
- ❌ 划分结果依赖于 `random_state`，不同 seed 会产生不同划分

### 2. 训练工具中的划分方式 (`scripts/train_utils.py`)

**位置**: 第 67-71 行

```python
# Dataset    
gss = sklearn.model_selection.GroupShuffleSplit(train_size=0.8,test_size=0.2, random_state=cfg.seed)
train_inds, test_inds = next(gss.split(X=range(len(dataset)), groups=dataset.csv.patientid))
train_dataset = xrv.datasets.SubsetDataset(dataset, train_inds)
valid_dataset = xrv.datasets.SubsetDataset(dataset, test_inds)
```

**问题**:
- ❌ **再次进行随机划分**，将传入的 `train_dataset` 重新划分为训练集和验证集
- ❌ 这导致最终的测试集实际上是从原始数据集的 20% 中再划分出来的，而不是使用预定义的测试集

## 数据集结构

### NIH_Dataset 图像标识

根据 `torchxrayvision/datasets.py` 第 506 行：
```python
imgid = self.csv['Image Index'].iloc[idx]
```

- NIH 数据集使用 `Image Index` 字段标识图像
- 划分文件中的文件名格式：`00000001_000.png`
- 这应该对应 `dataset.csv['Image Index']` 字段

## 问题总结

### 主要问题

1. **未使用预定义划分**: 代码完全忽略了 `/workspace/data/train_val_list.txt` 和 `test_list.txt` 文件
2. **双重随机划分**: 
   - 第一次在 `train_model.py` 中随机划分（80/20）
   - 第二次在 `train_utils.py` 中再次随机划分（80/20）
   - 最终测试集只占原始数据的 4%（20% × 20%）
3. **划分不一致**: 每次运行可能产生不同的划分结果，影响实验可复现性
4. **数据泄露风险**: 如果预定义划分有特定目的（如时间分割、患者分割），随机划分可能违反这些约束

## 建议的修复方案

### 方案 1: 使用预定义划分文件（推荐）

修改 `scripts/train_model.py`，根据文件名匹配使用预定义划分：

```python
import pandas as pd

# 读取预定义划分文件
train_val_list = pd.read_csv('/workspace/data/train_val_list.txt', header=None)[0].tolist()
test_list = pd.read_csv('/workspace/data/test_list.txt', header=None)[0].tolist()

# 转换为集合以便快速查找
train_val_set = set(train_val_list)
test_set = set(test_list)

# 根据 Image Index 匹配划分
train_val_inds = []
test_inds = []

for i, dataset in enumerate(datas):
    if hasattr(dataset, 'csv') and 'Image Index' in dataset.csv.columns:
        # 根据 Image Index 匹配
        train_val_mask = dataset.csv['Image Index'].isin(train_val_set)
        test_mask = dataset.csv['Image Index'].isin(test_set)
        
        train_val_inds.append(np.where(train_val_mask)[0])
        test_inds.append(np.where(test_mask)[0])
    else:
        # 对于没有 Image Index 的数据集，使用原来的随机划分
        gss = sklearn.model_selection.GroupShuffleSplit(train_size=0.8, test_size=0.2, random_state=cfg.seed)
        train_inds, test_inds = next(gss.split(X=range(len(dataset)), groups=dataset.csv.patientid))
        train_val_inds.append(train_inds)
        test_inds.append(test_inds)
```

### 方案 2: 修改 train_utils.py 使用预定义验证集

如果 `train_val_list.txt` 需要进一步划分为训练集和验证集，可以：

1. 在 `train_model.py` 中使用预定义划分创建 `train_val_dataset` 和 `test_dataset`
2. 在 `train_utils.py` 中，对 `train_val_dataset` 进行进一步划分（或使用另一个预定义文件）

### 方案 3: 创建新的划分文件

如果 `train_val_list.txt` 需要进一步划分为训练集和验证集，可以：
- 创建 `train_list.txt` 和 `val_list.txt` 两个文件
- 修改代码以支持三路划分（train/val/test）

## 验证步骤

修复后，建议进行以下验证：

1. **检查划分覆盖率**: 确保所有样本都被正确分配到某个集合
2. **检查无重叠**: 确保训练集、验证集、测试集之间无重叠
3. **检查样本数量**: 验证划分后的样本数量与预期一致
4. **检查可复现性**: 多次运行应产生相同的划分结果

## 结论

**当前代码没有正确使用预定义的数据集划分**，而是使用随机划分。这可能导致：
- 实验结果不可复现
- 测试集大小不正确
- 可能违反数据划分的原始设计意图（如患者级别的划分）

**建议立即修复**，使用预定义的划分文件以确保实验的一致性和可复现性。
