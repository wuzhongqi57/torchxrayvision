nohup: ignoring input
Namespace(f='', name='vit_test', output_dir='/workspace/torchxrayvision/experiment/output/nih-vit-vit_test', dataset='nih', dataset_dir='/workspace/data', model='vit', seed=0, cuda=True, num_epochs=10, batch_size=32, shuffle=True, lr=0.001, threads=4, taskweights=True, featurereg=False, weightreg=False, data_aug=True, data_aug_rot=45, data_aug_trans=0.15, data_aug_scale=0.15, label_concat=False, label_concat_reg=False, labelunion=False)
Compose(
    <torchxrayvision.datasets.ToPILImage object at 0x773be1c92450>
    RandomAffine(degrees=[-45.0, 45.0], translate=(0.15, 0.15), scale=(0.85, 1.15))
    ToTensor()
)
Using input resolution: 224x224 for model: vit
datas_names ['nih']
Lung Lesion doesn't exist. Adding nans instead.
Fracture doesn't exist. Adding nans instead.
Lung Opacity doesn't exist. Adding nans instead.
Enlarged Cardiomediastinum doesn't exist. Adding nans instead.
train_dataset.labels.shape (89864, 18)
test_dataset.labels.shape (22256, 18)
train_dataset SubsetDataset num_samples=89864
└ of NIH_Dataset num_samples=112120 views=['PA', 'AP'] data_aug=Compose(
      <torchxrayvision.datasets.ToPILImage object at 0x773be1c92450>
      RandomAffine(degrees=[-45.0, 45.0], translate=(0.15, 0.15), scale=(0.85, 1.15))
      ToTensor()
  )
test_dataset SubsetDataset num_samples=22256
└ of NIH_Dataset num_samples=112120 views=['PA', 'AP'] data_aug=Compose(
      <torchxrayvision.datasets.ToPILImage object at 0x773be1c92450>
      RandomAffine(degrees=[-45.0, 45.0], translate=(0.15, 0.15), scale=(0.85, 1.15))
      ToTensor()
  )
ViT model created with ImageNet pretrained backbone: True
ViT hidden dimension: 768
ViT classification head: 18 classes
Our config:
Namespace(f='', name='vit_test', output_dir='/workspace/torchxrayvision/experiment/output/nih-vit-vit_test', dataset='nih', dataset_dir='/workspace/data', model='vit', seed=0, cuda=True, num_epochs=10, batch_size=32, shuffle=True, lr=0.001, threads=4, taskweights=True, featurereg=False, weightreg=False, data_aug=True, data_aug_rot=45, data_aug_trans=0.15, data_aug_scale=0.15, label_concat=False, label_concat_reg=False, labelunion=False)
Using device: cuda
/workspace/torchxrayvision/experiment/output/nih-vit-vit_test
Adam (
Parameter Group 0
    amsgrad: True
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 1e-05
)
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 1 - Train [50/2236 (2.2%)] - Loss = 1.7863
Epoch 1 - Train [100/2236 (4.5%)] - Loss = 1.6991
Epoch 1 - Train [150/2236 (6.7%)] - Loss = 1.6555
Epoch 1 - Train [200/2236 (8.9%)] - Loss = 1.6406
Epoch 1 - Train [250/2236 (11.2%)] - Loss = 1.6443
Epoch 1 - Train [300/2236 (13.4%)] - Loss = 1.6426
Epoch 1 - Train [350/2236 (15.7%)] - Loss = 1.6375
Epoch 1 - Train [400/2236 (17.9%)] - Loss = 1.6420
Epoch 1 - Train [450/2236 (20.1%)] - Loss = 1.6446
Epoch 1 - Train [500/2236 (22.4%)] - Loss = 1.6456
Epoch 1 - Train [550/2236 (24.6%)] - Loss = 1.6396
Epoch 1 - Train [600/2236 (26.8%)] - Loss = 1.6418
Epoch 1 - Train [650/2236 (29.1%)] - Loss = 1.6397
Epoch 1 - Train [700/2236 (31.3%)] - Loss = 1.6377
Epoch 1 - Train [750/2236 (33.5%)] - Loss = 1.6344
Epoch 1 - Train [800/2236 (35.8%)] - Loss = 1.6394
Epoch 1 - Train [850/2236 (38.0%)] - Loss = 1.6388
Epoch 1 - Train [900/2236 (40.3%)] - Loss = 1.6327
Epoch 1 - Train [950/2236 (42.5%)] - Loss = 1.6263
Epoch 1 - Train [1000/2236 (44.7%)] - Loss = 1.6299
Epoch 1 - Train [1050/2236 (47.0%)] - Loss = 1.6259
Epoch 1 - Train [1100/2236 (49.2%)] - Loss = 1.6204
Epoch 1 - Train [1150/2236 (51.4%)] - Loss = 1.6200
Epoch 1 - Train [1200/2236 (53.7%)] - Loss = 1.6193
Epoch 1 - Train [1250/2236 (55.9%)] - Loss = 1.6200
Epoch 1 - Train [1300/2236 (58.1%)] - Loss = 1.6203
Epoch 1 - Train [1350/2236 (60.4%)] - Loss = 1.6180
Epoch 1 - Train [1400/2236 (62.6%)] - Loss = 1.6169
Epoch 1 - Train [1450/2236 (64.8%)] - Loss = 1.6153
Epoch 1 - Train [1500/2236 (67.1%)] - Loss = 1.6151
Epoch 1 - Train [1550/2236 (69.3%)] - Loss = 1.6136
Epoch 1 - Train [1600/2236 (71.6%)] - Loss = 1.6146
Epoch 1 - Train [1650/2236 (73.8%)] - Loss = 1.6143
Epoch 1 - Train [1700/2236 (76.0%)] - Loss = 1.6138
Epoch 1 - Train [1750/2236 (78.3%)] - Loss = 1.6156
Epoch 1 - Train [1800/2236 (80.5%)] - Loss = 1.6103
Epoch 1 - Train [1850/2236 (82.7%)] - Loss = 1.6078
Epoch 1 - Train [1900/2236 (85.0%)] - Loss = 1.6073
Epoch 1 - Train [1950/2236 (87.2%)] - Loss = 1.6051
Epoch 1 - Train [2000/2236 (89.4%)] - Loss = 1.6048
Epoch 1 - Train [2050/2236 (91.7%)] - Loss = 1.6038
Epoch 1 - Train [2100/2236 (93.9%)] - Loss = 1.6030
Epoch 1 - Train [2150/2236 (96.2%)] - Loss = 1.6031
Epoch 1 - Train [2200/2236 (98.4%)] - Loss = 1.6035
Epoch 1 - Train [2236/2236 (100.0%)] - Loss = 1.6040
Epoch 1 - Valid [50/573 (8.7%)] - Loss = 2.6910
Epoch 1 - Valid [100/573 (17.5%)] - Loss = 2.6533
Epoch 1 - Valid [150/573 (26.2%)] - Loss = 2.6625
Epoch 1 - Valid [200/573 (34.9%)] - Loss = 2.6248
Epoch 1 - Valid [250/573 (43.6%)] - Loss = 2.6301
Epoch 1 - Valid [300/573 (52.4%)] - Loss = 2.6241
Epoch 1 - Valid [350/573 (61.1%)] - Loss = 2.6265
Epoch 1 - Valid [400/573 (69.8%)] - Loss = 2.6162
Epoch 1 - Valid [450/573 (78.5%)] - Loss = 2.6228
Epoch 1 - Valid [500/573 (87.3%)] - Loss = 2.6096
Epoch 1 - Valid [550/573 (96.0%)] - Loss = 2.6047
Epoch 1 - Valid [573/573 (100.0%)] - Loss = 2.5985
Epoch 1 - Valid - Avg AUC = 0.5746
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 2 - Train [50/2236 (2.2%)] - Loss = 1.5759
Epoch 2 - Train [100/2236 (4.5%)] - Loss = 1.6276
Epoch 2 - Train [150/2236 (6.7%)] - Loss = 1.6112
Epoch 2 - Train [200/2236 (8.9%)] - Loss = 1.6158
Epoch 2 - Train [250/2236 (11.2%)] - Loss = 1.5987
Epoch 2 - Train [300/2236 (13.4%)] - Loss = 1.5908
Epoch 2 - Train [350/2236 (15.7%)] - Loss = 1.5880
Epoch 2 - Train [400/2236 (17.9%)] - Loss = 1.5912
Epoch 2 - Train [450/2236 (20.1%)] - Loss = 1.5923
Epoch 2 - Train [500/2236 (22.4%)] - Loss = 1.5873
Epoch 2 - Train [550/2236 (24.6%)] - Loss = 1.5798
Epoch 2 - Train [600/2236 (26.8%)] - Loss = 1.5804
Epoch 2 - Train [650/2236 (29.1%)] - Loss = 1.5784
Epoch 2 - Train [700/2236 (31.3%)] - Loss = 1.5802
Epoch 2 - Train [750/2236 (33.5%)] - Loss = 1.5763
Epoch 2 - Train [800/2236 (35.8%)] - Loss = 1.5803
Epoch 2 - Train [850/2236 (38.0%)] - Loss = 1.5839
Epoch 2 - Train [900/2236 (40.3%)] - Loss = 1.5843
Epoch 2 - Train [950/2236 (42.5%)] - Loss = 1.5841
Epoch 2 - Train [1000/2236 (44.7%)] - Loss = 1.5816
Epoch 2 - Train [1050/2236 (47.0%)] - Loss = 1.5842
Epoch 2 - Train [1100/2236 (49.2%)] - Loss = 1.5851
Epoch 2 - Train [1150/2236 (51.4%)] - Loss = 1.5805
Epoch 2 - Train [1200/2236 (53.7%)] - Loss = 1.5803
Epoch 2 - Train [1250/2236 (55.9%)] - Loss = 1.5813
Epoch 2 - Train [1300/2236 (58.1%)] - Loss = 1.5818
Epoch 2 - Train [1350/2236 (60.4%)] - Loss = 1.5810
Epoch 2 - Train [1400/2236 (62.6%)] - Loss = 1.5803
Epoch 2 - Train [1450/2236 (64.8%)] - Loss = 1.5789
Epoch 2 - Train [1500/2236 (67.1%)] - Loss = 1.5770
Epoch 2 - Train [1550/2236 (69.3%)] - Loss = 1.5775
Epoch 2 - Train [1600/2236 (71.6%)] - Loss = 1.5771
Epoch 2 - Train [1650/2236 (73.8%)] - Loss = 1.5772
Epoch 2 - Train [1700/2236 (76.0%)] - Loss = 1.5787
Epoch 2 - Train [1750/2236 (78.3%)] - Loss = 1.5788
Epoch 2 - Train [1800/2236 (80.5%)] - Loss = 1.5792
Epoch 2 - Train [1850/2236 (82.7%)] - Loss = 1.5800
Epoch 2 - Train [1900/2236 (85.0%)] - Loss = 1.5787
Epoch 2 - Train [1950/2236 (87.2%)] - Loss = 1.5803
Epoch 2 - Train [2000/2236 (89.4%)] - Loss = 1.5795
Epoch 2 - Train [2050/2236 (91.7%)] - Loss = 1.5815
Epoch 2 - Train [2100/2236 (93.9%)] - Loss = 1.5812
Epoch 2 - Train [2150/2236 (96.2%)] - Loss = 1.5810
Epoch 2 - Train [2200/2236 (98.4%)] - Loss = 1.5820
Epoch 2 - Train [2236/2236 (100.0%)] - Loss = 1.5830
Epoch 2 - Valid [50/573 (8.7%)] - Loss = 2.6065
Epoch 2 - Valid [100/573 (17.5%)] - Loss = 2.6036
Epoch 2 - Valid [150/573 (26.2%)] - Loss = 2.5709
Epoch 2 - Valid [200/573 (34.9%)] - Loss = 2.5621
Epoch 2 - Valid [250/573 (43.6%)] - Loss = 2.5646
Epoch 2 - Valid [300/573 (52.4%)] - Loss = 2.5683
Epoch 2 - Valid [350/573 (61.1%)] - Loss = 2.5653
Epoch 2 - Valid [400/573 (69.8%)] - Loss = 2.5720
Epoch 2 - Valid [450/573 (78.5%)] - Loss = 2.5776
Epoch 2 - Valid [500/573 (87.3%)] - Loss = 2.5780
Epoch 2 - Valid [550/573 (96.0%)] - Loss = 2.5787
Epoch 2 - Valid [573/573 (100.0%)] - Loss = 2.5809
Epoch 2 - Valid - Avg AUC = 0.5825
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 3 - Train [50/2236 (2.2%)] - Loss = 1.6430
Epoch 3 - Train [100/2236 (4.5%)] - Loss = 1.5931
Epoch 3 - Train [150/2236 (6.7%)] - Loss = 1.6096
Epoch 3 - Train [200/2236 (8.9%)] - Loss = 1.6011
Epoch 3 - Train [250/2236 (11.2%)] - Loss = 1.5902
Epoch 3 - Train [300/2236 (13.4%)] - Loss = 1.5823
Epoch 3 - Train [350/2236 (15.7%)] - Loss = 1.5921
Epoch 3 - Train [400/2236 (17.9%)] - Loss = 1.5833
Epoch 3 - Train [450/2236 (20.1%)] - Loss = 1.5875
Epoch 3 - Train [500/2236 (22.4%)] - Loss = 1.5895
Epoch 3 - Train [550/2236 (24.6%)] - Loss = 1.5896
Epoch 3 - Train [600/2236 (26.8%)] - Loss = 1.5824
Epoch 3 - Train [650/2236 (29.1%)] - Loss = 1.5849
Epoch 3 - Train [700/2236 (31.3%)] - Loss = 1.5870
Epoch 3 - Train [750/2236 (33.5%)] - Loss = 1.5794
Epoch 3 - Train [800/2236 (35.8%)] - Loss = 1.5771
Epoch 3 - Train [850/2236 (38.0%)] - Loss = 1.5713
Epoch 3 - Train [900/2236 (40.3%)] - Loss = 1.5736
Epoch 3 - Train [950/2236 (42.5%)] - Loss = 1.5750
Epoch 3 - Train [1000/2236 (44.7%)] - Loss = 1.5767
Epoch 3 - Train [1050/2236 (47.0%)] - Loss = 1.5747
Epoch 3 - Train [1100/2236 (49.2%)] - Loss = 1.5731
Epoch 3 - Train [1150/2236 (51.4%)] - Loss = 1.5699
Epoch 3 - Train [1200/2236 (53.7%)] - Loss = 1.5720
Epoch 3 - Train [1250/2236 (55.9%)] - Loss = 1.5738
Epoch 3 - Train [1300/2236 (58.1%)] - Loss = 1.5732
Epoch 3 - Train [1350/2236 (60.4%)] - Loss = 1.5751
Epoch 3 - Train [1400/2236 (62.6%)] - Loss = 1.5752
Epoch 3 - Train [1450/2236 (64.8%)] - Loss = 1.5757
Epoch 3 - Train [1500/2236 (67.1%)] - Loss = 1.5763
Epoch 3 - Train [1550/2236 (69.3%)] - Loss = 1.5775
Epoch 3 - Train [1600/2236 (71.6%)] - Loss = 1.5764
Epoch 3 - Train [1650/2236 (73.8%)] - Loss = 1.5872
Epoch 3 - Train [1700/2236 (76.0%)] - Loss = 1.5884
Epoch 3 - Train [1750/2236 (78.3%)] - Loss = 1.5884
Epoch 3 - Train [1800/2236 (80.5%)] - Loss = 1.5872
Epoch 3 - Train [1850/2236 (82.7%)] - Loss = 1.5876
Epoch 3 - Train [1900/2236 (85.0%)] - Loss = 1.5897
Epoch 3 - Train [1950/2236 (87.2%)] - Loss = 1.5900
Epoch 3 - Train [2000/2236 (89.4%)] - Loss = 1.5910
Epoch 3 - Train [2050/2236 (91.7%)] - Loss = 1.5914
Epoch 3 - Train [2100/2236 (93.9%)] - Loss = 1.5928
Epoch 3 - Train [2150/2236 (96.2%)] - Loss = 1.5929
Epoch 3 - Train [2200/2236 (98.4%)] - Loss = 1.5921
Epoch 3 - Train [2236/2236 (100.0%)] - Loss = 1.5915
Epoch 3 - Valid [50/573 (8.7%)] - Loss = 2.7093
Epoch 3 - Valid [100/573 (17.5%)] - Loss = 2.7248
Epoch 3 - Valid [150/573 (26.2%)] - Loss = 2.6626
Epoch 3 - Valid [200/573 (34.9%)] - Loss = 2.6512
Epoch 3 - Valid [250/573 (43.6%)] - Loss = 2.6400
Epoch 3 - Valid [300/573 (52.4%)] - Loss = 2.6416
Epoch 3 - Valid [350/573 (61.1%)] - Loss = 2.6443
Epoch 3 - Valid [400/573 (69.8%)] - Loss = 2.6323
Epoch 3 - Valid [450/573 (78.5%)] - Loss = 2.6377
Epoch 3 - Valid [500/573 (87.3%)] - Loss = 2.6327
Epoch 3 - Valid [550/573 (96.0%)] - Loss = 2.6205
Epoch 3 - Valid [573/573 (100.0%)] - Loss = 2.6195
Epoch 3 - Valid - Avg AUC = 0.5770
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 4 - Train [50/2236 (2.2%)] - Loss = 1.6190
Epoch 4 - Train [100/2236 (4.5%)] - Loss = 1.5963
Epoch 4 - Train [150/2236 (6.7%)] - Loss = 1.5626
Epoch 4 - Train [200/2236 (8.9%)] - Loss = 1.5751
Epoch 4 - Train [250/2236 (11.2%)] - Loss = 1.5620
Epoch 4 - Train [300/2236 (13.4%)] - Loss = 1.5792
Epoch 4 - Train [350/2236 (15.7%)] - Loss = 1.5779
Epoch 4 - Train [400/2236 (17.9%)] - Loss = 1.5924
Epoch 4 - Train [450/2236 (20.1%)] - Loss = 1.5881
Epoch 4 - Train [500/2236 (22.4%)] - Loss = 1.5809
Epoch 4 - Train [550/2236 (24.6%)] - Loss = 1.5752
Epoch 4 - Train [600/2236 (26.8%)] - Loss = 1.5789
Epoch 4 - Train [650/2236 (29.1%)] - Loss = 1.5726
Epoch 4 - Train [700/2236 (31.3%)] - Loss = 1.5738
Epoch 4 - Train [750/2236 (33.5%)] - Loss = 1.5732
Epoch 4 - Train [800/2236 (35.8%)] - Loss = 1.5692
Epoch 4 - Train [850/2236 (38.0%)] - Loss = 1.5676
Epoch 4 - Train [900/2236 (40.3%)] - Loss = 1.5691
Epoch 4 - Train [950/2236 (42.5%)] - Loss = 1.5737
Epoch 4 - Train [1000/2236 (44.7%)] - Loss = 1.5741
Epoch 4 - Train [1050/2236 (47.0%)] - Loss = 1.5736
Epoch 4 - Train [1100/2236 (49.2%)] - Loss = 1.5744
Epoch 4 - Train [1150/2236 (51.4%)] - Loss = 1.5728
Epoch 4 - Train [1200/2236 (53.7%)] - Loss = 1.5701
Epoch 4 - Train [1250/2236 (55.9%)] - Loss = 1.5743
Epoch 4 - Train [1300/2236 (58.1%)] - Loss = 1.5727
Epoch 4 - Train [1350/2236 (60.4%)] - Loss = 1.5748
Epoch 4 - Train [1400/2236 (62.6%)] - Loss = 1.5763
Epoch 4 - Train [1450/2236 (64.8%)] - Loss = 1.5766
Epoch 4 - Train [1500/2236 (67.1%)] - Loss = 1.5758
Epoch 4 - Train [1550/2236 (69.3%)] - Loss = 1.5767
Epoch 4 - Train [1600/2236 (71.6%)] - Loss = 1.5784
Epoch 4 - Train [1650/2236 (73.8%)] - Loss = 1.5814
Epoch 4 - Train [1700/2236 (76.0%)] - Loss = 1.5818
Epoch 4 - Train [1750/2236 (78.3%)] - Loss = 1.5838
Epoch 4 - Train [1800/2236 (80.5%)] - Loss = 1.5827
Epoch 4 - Train [1850/2236 (82.7%)] - Loss = 1.5813
Epoch 4 - Train [1900/2236 (85.0%)] - Loss = 1.5806
Epoch 4 - Train [1950/2236 (87.2%)] - Loss = 1.5799
Epoch 4 - Train [2000/2236 (89.4%)] - Loss = 1.5808
Epoch 4 - Train [2050/2236 (91.7%)] - Loss = 1.5808
Epoch 4 - Train [2100/2236 (93.9%)] - Loss = 1.5803
Epoch 4 - Train [2150/2236 (96.2%)] - Loss = 1.5807
Epoch 4 - Train [2200/2236 (98.4%)] - Loss = 1.5803
Epoch 4 - Train [2236/2236 (100.0%)] - Loss = 1.5809
Epoch 4 - Valid [50/573 (8.7%)] - Loss = 2.5741
Epoch 4 - Valid [100/573 (17.5%)] - Loss = 2.6204
Epoch 4 - Valid [150/573 (26.2%)] - Loss = 2.5982
Epoch 4 - Valid [200/573 (34.9%)] - Loss = 2.5967
Epoch 4 - Valid [250/573 (43.6%)] - Loss = 2.5735
Epoch 4 - Valid [300/573 (52.4%)] - Loss = 2.5788
Epoch 4 - Valid [350/573 (61.1%)] - Loss = 2.5677
Epoch 4 - Valid [400/573 (69.8%)] - Loss = 2.5651
Epoch 4 - Valid [450/573 (78.5%)] - Loss = 2.5661
Epoch 4 - Valid [500/573 (87.3%)] - Loss = 2.5775
Epoch 4 - Valid [550/573 (96.0%)] - Loss = 2.5925
Epoch 4 - Valid [573/573 (100.0%)] - Loss = 2.5877
Epoch 4 - Valid - Avg AUC = 0.5888
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 5 - Train [50/2236 (2.2%)] - Loss = 1.5295
Epoch 5 - Train [100/2236 (4.5%)] - Loss = 1.5519
Epoch 5 - Train [150/2236 (6.7%)] - Loss = 1.5586
Epoch 5 - Train [200/2236 (8.9%)] - Loss = 1.5539
Epoch 5 - Train [250/2236 (11.2%)] - Loss = 1.5679
Epoch 5 - Train [300/2236 (13.4%)] - Loss = 1.5766
Epoch 5 - Train [350/2236 (15.7%)] - Loss = 1.5689
Epoch 5 - Train [400/2236 (17.9%)] - Loss = 1.5712
Epoch 5 - Train [450/2236 (20.1%)] - Loss = 1.5795
Epoch 5 - Train [500/2236 (22.4%)] - Loss = 1.5684
Epoch 5 - Train [550/2236 (24.6%)] - Loss = 1.5663
Epoch 5 - Train [600/2236 (26.8%)] - Loss = 1.5676
Epoch 5 - Train [650/2236 (29.1%)] - Loss = 1.5692
Epoch 5 - Train [700/2236 (31.3%)] - Loss = 1.5684
Epoch 5 - Train [750/2236 (33.5%)] - Loss = 1.5649
Epoch 5 - Train [800/2236 (35.8%)] - Loss = 1.5726
Epoch 5 - Train [850/2236 (38.0%)] - Loss = 1.5739
Epoch 5 - Train [900/2236 (40.3%)] - Loss = 1.5754
Epoch 5 - Train [950/2236 (42.5%)] - Loss = 1.5785
Epoch 5 - Train [1000/2236 (44.7%)] - Loss = 1.5759
Epoch 5 - Train [1050/2236 (47.0%)] - Loss = 1.5742
Epoch 5 - Train [1100/2236 (49.2%)] - Loss = 1.5722
Epoch 5 - Train [1150/2236 (51.4%)] - Loss = 1.5757
Epoch 5 - Train [1200/2236 (53.7%)] - Loss = 1.5781
Epoch 5 - Train [1250/2236 (55.9%)] - Loss = 1.5755
Epoch 5 - Train [1300/2236 (58.1%)] - Loss = 1.5738
Epoch 5 - Train [1350/2236 (60.4%)] - Loss = 1.5734
Epoch 5 - Train [1400/2236 (62.6%)] - Loss = 1.5736
Epoch 5 - Train [1450/2236 (64.8%)] - Loss = 1.5727
Epoch 5 - Train [1500/2236 (67.1%)] - Loss = 1.5746
Epoch 5 - Train [1550/2236 (69.3%)] - Loss = 1.5740
Epoch 5 - Train [1600/2236 (71.6%)] - Loss = 1.5730
Epoch 5 - Train [1650/2236 (73.8%)] - Loss = 1.5749
Epoch 5 - Train [1700/2236 (76.0%)] - Loss = 1.5757
Epoch 5 - Train [1750/2236 (78.3%)] - Loss = 1.5746
Epoch 5 - Train [1800/2236 (80.5%)] - Loss = 1.5739
Epoch 5 - Train [1850/2236 (82.7%)] - Loss = 1.5731
Epoch 5 - Train [1900/2236 (85.0%)] - Loss = 1.5736
Epoch 5 - Train [1950/2236 (87.2%)] - Loss = 1.5729
Epoch 5 - Train [2000/2236 (89.4%)] - Loss = 1.5737
Epoch 5 - Train [2050/2236 (91.7%)] - Loss = 1.5732
Epoch 5 - Train [2100/2236 (93.9%)] - Loss = 1.5723
Epoch 5 - Train [2150/2236 (96.2%)] - Loss = 1.5723
Epoch 5 - Train [2200/2236 (98.4%)] - Loss = 1.5722
Epoch 5 - Train [2236/2236 (100.0%)] - Loss = 1.5703
Epoch 5 - Valid [50/573 (8.7%)] - Loss = 2.4977
Epoch 5 - Valid [100/573 (17.5%)] - Loss = 2.5341
Epoch 5 - Valid [150/573 (26.2%)] - Loss = 2.5511
Epoch 5 - Valid [200/573 (34.9%)] - Loss = 2.5663
Epoch 5 - Valid [250/573 (43.6%)] - Loss = 2.5623
Epoch 5 - Valid [300/573 (52.4%)] - Loss = 2.5610
Epoch 5 - Valid [350/573 (61.1%)] - Loss = 2.5690
Epoch 5 - Valid [400/573 (69.8%)] - Loss = 2.5764
Epoch 5 - Valid [450/573 (78.5%)] - Loss = 2.5766
Epoch 5 - Valid [500/573 (87.3%)] - Loss = 2.5765
Epoch 5 - Valid [550/573 (96.0%)] - Loss = 2.5725
Epoch 5 - Valid [573/573 (100.0%)] - Loss = 2.5652
Epoch 5 - Valid - Avg AUC = 0.6030
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 6 - Train [50/2236 (2.2%)] - Loss = 1.5427
Epoch 6 - Train [100/2236 (4.5%)] - Loss = 1.5793
Epoch 6 - Train [150/2236 (6.7%)] - Loss = 1.5748
Epoch 6 - Train [200/2236 (8.9%)] - Loss = 1.5563
Epoch 6 - Train [250/2236 (11.2%)] - Loss = 1.5488
Epoch 6 - Train [300/2236 (13.4%)] - Loss = 1.5471
Epoch 6 - Train [350/2236 (15.7%)] - Loss = 1.5454
Epoch 6 - Train [400/2236 (17.9%)] - Loss = 1.5384
Epoch 6 - Train [450/2236 (20.1%)] - Loss = 1.5382
Epoch 6 - Train [500/2236 (22.4%)] - Loss = 1.5465
Epoch 6 - Train [550/2236 (24.6%)] - Loss = 1.5500
Epoch 6 - Train [600/2236 (26.8%)] - Loss = 1.5587
Epoch 6 - Train [650/2236 (29.1%)] - Loss = 1.5532
Epoch 6 - Train [700/2236 (31.3%)] - Loss = 1.5535
Epoch 6 - Train [750/2236 (33.5%)] - Loss = 1.5537
Epoch 6 - Train [800/2236 (35.8%)] - Loss = 1.5542
Epoch 6 - Train [850/2236 (38.0%)] - Loss = 1.5542
Epoch 6 - Train [900/2236 (40.3%)] - Loss = 1.5556
Epoch 6 - Train [950/2236 (42.5%)] - Loss = 1.5553
Epoch 6 - Train [1000/2236 (44.7%)] - Loss = 1.5583
Epoch 6 - Train [1050/2236 (47.0%)] - Loss = 1.5588
Epoch 6 - Train [1100/2236 (49.2%)] - Loss = 1.5602
Epoch 6 - Train [1150/2236 (51.4%)] - Loss = 1.5621
Epoch 6 - Train [1200/2236 (53.7%)] - Loss = 1.5621
Epoch 6 - Train [1250/2236 (55.9%)] - Loss = 1.5648
Epoch 6 - Train [1300/2236 (58.1%)] - Loss = 1.5645
Epoch 6 - Train [1350/2236 (60.4%)] - Loss = 1.5636
Epoch 6 - Train [1400/2236 (62.6%)] - Loss = 1.5656
Epoch 6 - Train [1450/2236 (64.8%)] - Loss = 1.5655
Epoch 6 - Train [1500/2236 (67.1%)] - Loss = 1.5673
Epoch 6 - Train [1550/2236 (69.3%)] - Loss = 1.5667
Epoch 6 - Train [1600/2236 (71.6%)] - Loss = 1.5660
Epoch 6 - Train [1650/2236 (73.8%)] - Loss = 1.5673
Epoch 6 - Train [1700/2236 (76.0%)] - Loss = 1.5687
Epoch 6 - Train [1750/2236 (78.3%)] - Loss = 1.5668
Epoch 6 - Train [1800/2236 (80.5%)] - Loss = 1.5637
Epoch 6 - Train [1850/2236 (82.7%)] - Loss = 1.5615
Epoch 6 - Train [1900/2236 (85.0%)] - Loss = 1.5634
Epoch 6 - Train [1950/2236 (87.2%)] - Loss = 1.5651
Epoch 6 - Train [2000/2236 (89.4%)] - Loss = 1.5649
Epoch 6 - Train [2050/2236 (91.7%)] - Loss = 1.5632
Epoch 6 - Train [2100/2236 (93.9%)] - Loss = 1.5622
Epoch 6 - Train [2150/2236 (96.2%)] - Loss = 1.5623
Epoch 6 - Train [2200/2236 (98.4%)] - Loss = 1.5631
Epoch 6 - Train [2236/2236 (100.0%)] - Loss = 1.5634
Epoch 6 - Valid [50/573 (8.7%)] - Loss = 2.4869
Epoch 6 - Valid [100/573 (17.5%)] - Loss = 2.5372
Epoch 6 - Valid [150/573 (26.2%)] - Loss = 2.5577
Epoch 6 - Valid [200/573 (34.9%)] - Loss = 2.5456
Epoch 6 - Valid [250/573 (43.6%)] - Loss = 2.5574
Epoch 6 - Valid [300/573 (52.4%)] - Loss = 2.5631
Epoch 6 - Valid [350/573 (61.1%)] - Loss = 2.5588
Epoch 6 - Valid [400/573 (69.8%)] - Loss = 2.5601
Epoch 6 - Valid [450/573 (78.5%)] - Loss = 2.5578
Epoch 6 - Valid [500/573 (87.3%)] - Loss = 2.5625
Epoch 6 - Valid [550/573 (96.0%)] - Loss = 2.5555
Epoch 6 - Valid [573/573 (100.0%)] - Loss = 2.5574
Epoch 6 - Valid - Avg AUC = 0.6143
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 7 - Train [50/2236 (2.2%)] - Loss = 1.4946
Epoch 7 - Train [100/2236 (4.5%)] - Loss = 1.5042
Epoch 7 - Train [150/2236 (6.7%)] - Loss = 1.5371
Epoch 7 - Train [200/2236 (8.9%)] - Loss = 1.5547
Epoch 7 - Train [250/2236 (11.2%)] - Loss = 1.5713
Epoch 7 - Train [300/2236 (13.4%)] - Loss = 1.5757
Epoch 7 - Train [350/2236 (15.7%)] - Loss = 1.5652
Epoch 7 - Train [400/2236 (17.9%)] - Loss = 1.5660
Epoch 7 - Train [450/2236 (20.1%)] - Loss = 1.5593
Epoch 7 - Train [500/2236 (22.4%)] - Loss = 1.5595
Epoch 7 - Train [550/2236 (24.6%)] - Loss = 1.5607
Epoch 7 - Train [600/2236 (26.8%)] - Loss = 1.5587
Epoch 7 - Train [650/2236 (29.1%)] - Loss = 1.5568
Epoch 7 - Train [700/2236 (31.3%)] - Loss = 1.5532
Epoch 7 - Train [750/2236 (33.5%)] - Loss = 1.5595
Epoch 7 - Train [800/2236 (35.8%)] - Loss = 1.5592
Epoch 7 - Train [850/2236 (38.0%)] - Loss = 1.5535
Epoch 7 - Train [900/2236 (40.3%)] - Loss = 1.5513
Epoch 7 - Train [950/2236 (42.5%)] - Loss = 1.5515
Epoch 7 - Train [1000/2236 (44.7%)] - Loss = 1.5531
Epoch 7 - Train [1050/2236 (47.0%)] - Loss = 1.5566
Epoch 7 - Train [1100/2236 (49.2%)] - Loss = 1.5576
Epoch 7 - Train [1150/2236 (51.4%)] - Loss = 1.5606
Epoch 7 - Train [1200/2236 (53.7%)] - Loss = 1.5604
Epoch 7 - Train [1250/2236 (55.9%)] - Loss = 1.5600
Epoch 7 - Train [1300/2236 (58.1%)] - Loss = 1.5609
Epoch 7 - Train [1350/2236 (60.4%)] - Loss = 1.5593
Epoch 7 - Train [1400/2236 (62.6%)] - Loss = 1.5623
Epoch 7 - Train [1450/2236 (64.8%)] - Loss = 1.5618
Epoch 7 - Train [1500/2236 (67.1%)] - Loss = 1.5610
Epoch 7 - Train [1550/2236 (69.3%)] - Loss = 1.5610
Epoch 7 - Train [1600/2236 (71.6%)] - Loss = 1.5604
Epoch 7 - Train [1650/2236 (73.8%)] - Loss = 1.5615
Epoch 7 - Train [1700/2236 (76.0%)] - Loss = 1.5635
Epoch 7 - Train [1750/2236 (78.3%)] - Loss = 1.5635
Epoch 7 - Train [1800/2236 (80.5%)] - Loss = 1.5615
Epoch 7 - Train [1850/2236 (82.7%)] - Loss = 1.5607
Epoch 7 - Train [1900/2236 (85.0%)] - Loss = 1.5585
Epoch 7 - Train [1950/2236 (87.2%)] - Loss = 1.5584
Epoch 7 - Train [2000/2236 (89.4%)] - Loss = 1.5588
Epoch 7 - Train [2050/2236 (91.7%)] - Loss = 1.5579
Epoch 7 - Train [2100/2236 (93.9%)] - Loss = 1.5588
Epoch 7 - Train [2150/2236 (96.2%)] - Loss = 1.5585
Epoch 7 - Train [2200/2236 (98.4%)] - Loss = 1.5580
Epoch 7 - Train [2236/2236 (100.0%)] - Loss = 1.5587
Epoch 7 - Valid [50/573 (8.7%)] - Loss = 2.6307
Epoch 7 - Valid [100/573 (17.5%)] - Loss = 2.5538
Epoch 7 - Valid [150/573 (26.2%)] - Loss = 2.5635
Epoch 7 - Valid [200/573 (34.9%)] - Loss = 2.5501
Epoch 7 - Valid [250/573 (43.6%)] - Loss = 2.5643
Epoch 7 - Valid [300/573 (52.4%)] - Loss = 2.5622
Epoch 7 - Valid [350/573 (61.1%)] - Loss = 2.5555
Epoch 7 - Valid [400/573 (69.8%)] - Loss = 2.5487
Epoch 7 - Valid [450/573 (78.5%)] - Loss = 2.5521
Epoch 7 - Valid [500/573 (87.3%)] - Loss = 2.5550
Epoch 7 - Valid [550/573 (96.0%)] - Loss = 2.5513
Epoch 7 - Valid [573/573 (100.0%)] - Loss = 2.5520
Epoch 7 - Valid - Avg AUC = 0.6181
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 8 - Train [50/2236 (2.2%)] - Loss = 1.4759
Epoch 8 - Train [100/2236 (4.5%)] - Loss = 1.5153
Epoch 8 - Train [150/2236 (6.7%)] - Loss = 1.5322
Epoch 8 - Train [200/2236 (8.9%)] - Loss = 1.5333
Epoch 8 - Train [250/2236 (11.2%)] - Loss = 1.5405
Epoch 8 - Train [300/2236 (13.4%)] - Loss = 1.5514
Epoch 8 - Train [350/2236 (15.7%)] - Loss = 1.5595
Epoch 8 - Train [400/2236 (17.9%)] - Loss = 1.5615
Epoch 8 - Train [450/2236 (20.1%)] - Loss = 1.5602
Epoch 8 - Train [500/2236 (22.4%)] - Loss = 1.5640
Epoch 8 - Train [550/2236 (24.6%)] - Loss = 1.5673
Epoch 8 - Train [600/2236 (26.8%)] - Loss = 1.5683
Epoch 8 - Train [650/2236 (29.1%)] - Loss = 1.5728
Epoch 8 - Train [700/2236 (31.3%)] - Loss = 1.5726
Epoch 8 - Train [750/2236 (33.5%)] - Loss = 1.5726
Epoch 8 - Train [800/2236 (35.8%)] - Loss = 1.5674
Epoch 8 - Train [850/2236 (38.0%)] - Loss = 1.5678
Epoch 8 - Train [900/2236 (40.3%)] - Loss = 1.5625
Epoch 8 - Train [950/2236 (42.5%)] - Loss = 1.5614
Epoch 8 - Train [1000/2236 (44.7%)] - Loss = 1.5652
Epoch 8 - Train [1050/2236 (47.0%)] - Loss = 1.5645
Epoch 8 - Train [1100/2236 (49.2%)] - Loss = 1.5640
Epoch 8 - Train [1150/2236 (51.4%)] - Loss = 1.5650
Epoch 8 - Train [1200/2236 (53.7%)] - Loss = 1.5639
Epoch 8 - Train [1250/2236 (55.9%)] - Loss = 1.5628
Epoch 8 - Train [1300/2236 (58.1%)] - Loss = 1.5601
Epoch 8 - Train [1350/2236 (60.4%)] - Loss = 1.5611
Epoch 8 - Train [1400/2236 (62.6%)] - Loss = 1.5567
Epoch 8 - Train [1450/2236 (64.8%)] - Loss = 1.5552
Epoch 8 - Train [1500/2236 (67.1%)] - Loss = 1.5540
Epoch 8 - Train [1550/2236 (69.3%)] - Loss = 1.5550
Epoch 8 - Train [1600/2236 (71.6%)] - Loss = 1.5583
Epoch 8 - Train [1650/2236 (73.8%)] - Loss = 1.5600
Epoch 8 - Train [1700/2236 (76.0%)] - Loss = 1.5584
Epoch 8 - Train [1750/2236 (78.3%)] - Loss = 1.5579
Epoch 8 - Train [1800/2236 (80.5%)] - Loss = 1.5560
Epoch 8 - Train [1850/2236 (82.7%)] - Loss = 1.5560
Epoch 8 - Train [1900/2236 (85.0%)] - Loss = 1.5546
Epoch 8 - Train [1950/2236 (87.2%)] - Loss = 1.5547
Epoch 8 - Train [2000/2236 (89.4%)] - Loss = 1.5521
Epoch 8 - Train [2050/2236 (91.7%)] - Loss = 1.5523
Epoch 8 - Train [2100/2236 (93.9%)] - Loss = 1.5517
Epoch 8 - Train [2150/2236 (96.2%)] - Loss = 1.5516
Epoch 8 - Train [2200/2236 (98.4%)] - Loss = 1.5538
Epoch 8 - Train [2236/2236 (100.0%)] - Loss = 1.5549
Epoch 8 - Valid [50/573 (8.7%)] - Loss = 2.4743
Epoch 8 - Valid [100/573 (17.5%)] - Loss = 2.5371
Epoch 8 - Valid [150/573 (26.2%)] - Loss = 2.5492
Epoch 8 - Valid [200/573 (34.9%)] - Loss = 2.5497
Epoch 8 - Valid [250/573 (43.6%)] - Loss = 2.5619
Epoch 8 - Valid [300/573 (52.4%)] - Loss = 2.5653
Epoch 8 - Valid [350/573 (61.1%)] - Loss = 2.5592
Epoch 8 - Valid [400/573 (69.8%)] - Loss = 2.5531
Epoch 8 - Valid [450/573 (78.5%)] - Loss = 2.5599
Epoch 8 - Valid [500/573 (87.3%)] - Loss = 2.5500
Epoch 8 - Valid [550/573 (96.0%)] - Loss = 2.5471
Epoch 8 - Valid [573/573 (100.0%)] - Loss = 2.5492
Epoch 8 - Valid - Avg AUC = 0.6317
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 9 - Train [50/2236 (2.2%)] - Loss = 1.5709
Epoch 9 - Train [100/2236 (4.5%)] - Loss = 1.5893
Epoch 9 - Train [150/2236 (6.7%)] - Loss = 1.5749
Epoch 9 - Train [200/2236 (8.9%)] - Loss = 1.5807
Epoch 9 - Train [250/2236 (11.2%)] - Loss = 1.5690
Epoch 9 - Train [300/2236 (13.4%)] - Loss = 1.5674
Epoch 9 - Train [350/2236 (15.7%)] - Loss = 1.5717
Epoch 9 - Train [400/2236 (17.9%)] - Loss = 1.5727
Epoch 9 - Train [450/2236 (20.1%)] - Loss = 1.5692
Epoch 9 - Train [500/2236 (22.4%)] - Loss = 1.5619
Epoch 9 - Train [550/2236 (24.6%)] - Loss = 1.5591
Epoch 9 - Train [600/2236 (26.8%)] - Loss = 1.5573
Epoch 9 - Train [650/2236 (29.1%)] - Loss = 1.5556
Epoch 9 - Train [700/2236 (31.3%)] - Loss = 1.5535
Epoch 9 - Train [750/2236 (33.5%)] - Loss = 1.5589
Epoch 9 - Train [800/2236 (35.8%)] - Loss = 1.5595
Epoch 9 - Train [850/2236 (38.0%)] - Loss = 1.5633
Epoch 9 - Train [900/2236 (40.3%)] - Loss = 1.5607
Epoch 9 - Train [950/2236 (42.5%)] - Loss = 1.5611
Epoch 9 - Train [1000/2236 (44.7%)] - Loss = 1.5601
Epoch 9 - Train [1050/2236 (47.0%)] - Loss = 1.5620
Epoch 9 - Train [1100/2236 (49.2%)] - Loss = 1.5613
Epoch 9 - Train [1150/2236 (51.4%)] - Loss = 1.5610
Epoch 9 - Train [1200/2236 (53.7%)] - Loss = 1.5605
Epoch 9 - Train [1250/2236 (55.9%)] - Loss = 1.5576
Epoch 9 - Train [1300/2236 (58.1%)] - Loss = 1.5579
Epoch 9 - Train [1350/2236 (60.4%)] - Loss = 1.5586
Epoch 9 - Train [1400/2236 (62.6%)] - Loss = 1.5583
Epoch 9 - Train [1450/2236 (64.8%)] - Loss = 1.5542
Epoch 9 - Train [1500/2236 (67.1%)] - Loss = 1.5517
Epoch 9 - Train [1550/2236 (69.3%)] - Loss = 1.5510
Epoch 9 - Train [1600/2236 (71.6%)] - Loss = 1.5518
Epoch 9 - Train [1650/2236 (73.8%)] - Loss = 1.5517
Epoch 9 - Train [1700/2236 (76.0%)] - Loss = 1.5492
Epoch 9 - Train [1750/2236 (78.3%)] - Loss = 1.5497
Epoch 9 - Train [1800/2236 (80.5%)] - Loss = 1.5499
Epoch 9 - Train [1850/2236 (82.7%)] - Loss = 1.5505
Epoch 9 - Train [1900/2236 (85.0%)] - Loss = 1.5508
Epoch 9 - Train [1950/2236 (87.2%)] - Loss = 1.5509
Epoch 9 - Train [2000/2236 (89.4%)] - Loss = 1.5508
Epoch 9 - Train [2050/2236 (91.7%)] - Loss = 1.5514
Epoch 9 - Train [2100/2236 (93.9%)] - Loss = 1.5491
Epoch 9 - Train [2150/2236 (96.2%)] - Loss = 1.5491
Epoch 9 - Train [2200/2236 (98.4%)] - Loss = 1.5489
Epoch 9 - Train [2236/2236 (100.0%)] - Loss = 1.5494
Epoch 9 - Valid [50/573 (8.7%)] - Loss = 2.6172
Epoch 9 - Valid [100/573 (17.5%)] - Loss = 2.6111
Epoch 9 - Valid [150/573 (26.2%)] - Loss = 2.5893
Epoch 9 - Valid [200/573 (34.9%)] - Loss = 2.5757
Epoch 9 - Valid [250/573 (43.6%)] - Loss = 2.5629
Epoch 9 - Valid [300/573 (52.4%)] - Loss = 2.5456
Epoch 9 - Valid [350/573 (61.1%)] - Loss = 2.5399
Epoch 9 - Valid [400/573 (69.8%)] - Loss = 2.5316
Epoch 9 - Valid [450/573 (78.5%)] - Loss = 2.5245
Epoch 9 - Valid [500/573 (87.3%)] - Loss = 2.5304
Epoch 9 - Valid [550/573 (96.0%)] - Loss = 2.5367
Epoch 9 - Valid [573/573 (100.0%)] - Loss = 2.5299
Epoch 9 - Valid - Avg AUC = 0.6355
task weights tensor([0.5240, 0.8089, 0.1850, 0.7793, 0.9072, 0.8918, 0.9297, 0.4585, 0.9414,
        0.8618, 0.8865, 0.7379, 0.7665, 0.9911, 1.0000, 1.0000, 1.0000, 1.0000],
       device='cuda:0')
Epoch 10 - Train [50/2236 (2.2%)] - Loss = 1.5740
Epoch 10 - Train [100/2236 (4.5%)] - Loss = 1.5268
Epoch 10 - Train [150/2236 (6.7%)] - Loss = 1.5093
Epoch 10 - Train [200/2236 (8.9%)] - Loss = 1.5071
Epoch 10 - Train [250/2236 (11.2%)] - Loss = 1.5235
Epoch 10 - Train [300/2236 (13.4%)] - Loss = 1.5334
Epoch 10 - Train [350/2236 (15.7%)] - Loss = 1.5423
Epoch 10 - Train [400/2236 (17.9%)] - Loss = 1.5398
Epoch 10 - Train [450/2236 (20.1%)] - Loss = 1.5490
Epoch 10 - Train [500/2236 (22.4%)] - Loss = 1.5514
Epoch 10 - Train [550/2236 (24.6%)] - Loss = 1.5603
Epoch 10 - Train [600/2236 (26.8%)] - Loss = 1.5606
Epoch 10 - Train [650/2236 (29.1%)] - Loss = 1.5608
Epoch 10 - Train [700/2236 (31.3%)] - Loss = 1.5568
Epoch 10 - Train [750/2236 (33.5%)] - Loss = 1.5619
Epoch 10 - Train [800/2236 (35.8%)] - Loss = 1.5567
Epoch 10 - Train [850/2236 (38.0%)] - Loss = 1.5577
Epoch 10 - Train [900/2236 (40.3%)] - Loss = 1.5559
Epoch 10 - Train [950/2236 (42.5%)] - Loss = 1.5574
Epoch 10 - Train [1000/2236 (44.7%)] - Loss = 1.5579
Epoch 10 - Train [1050/2236 (47.0%)] - Loss = 1.5549
Epoch 10 - Train [1100/2236 (49.2%)] - Loss = 1.5518
Epoch 10 - Train [1150/2236 (51.4%)] - Loss = 1.5503
Epoch 10 - Train [1200/2236 (53.7%)] - Loss = 1.5503
Epoch 10 - Train [1250/2236 (55.9%)] - Loss = 1.5512
Epoch 10 - Train [1300/2236 (58.1%)] - Loss = 1.5515
Epoch 10 - Train [1350/2236 (60.4%)] - Loss = 1.5505
Epoch 10 - Train [1400/2236 (62.6%)] - Loss = 1.5488
Epoch 10 - Train [1450/2236 (64.8%)] - Loss = 1.5479
Epoch 10 - Train [1500/2236 (67.1%)] - Loss = 1.5462
Epoch 10 - Train [1550/2236 (69.3%)] - Loss = 1.5476
Epoch 10 - Train [1600/2236 (71.6%)] - Loss = 1.5476
Epoch 10 - Train [1650/2236 (73.8%)] - Loss = 1.5473
Epoch 10 - Train [1700/2236 (76.0%)] - Loss = 1.5478
Epoch 10 - Train [1750/2236 (78.3%)] - Loss = 1.5450
Epoch 10 - Train [1800/2236 (80.5%)] - Loss = 1.5444
Epoch 10 - Train [1850/2236 (82.7%)] - Loss = 1.5415
Epoch 10 - Train [1900/2236 (85.0%)] - Loss = 1.5389
Epoch 10 - Train [1950/2236 (87.2%)] - Loss = 1.5393
Epoch 10 - Train [2000/2236 (89.4%)] - Loss = 1.5398
Epoch 10 - Train [2050/2236 (91.7%)] - Loss = 1.5415
Epoch 10 - Train [2100/2236 (93.9%)] - Loss = 1.5430
Epoch 10 - Train [2150/2236 (96.2%)] - Loss = 1.5452
Epoch 10 - Train [2200/2236 (98.4%)] - Loss = 1.5449
Epoch 10 - Train [2236/2236 (100.0%)] - Loss = 1.5446
Epoch 10 - Valid [50/573 (8.7%)] - Loss = 2.4806
Epoch 10 - Valid [100/573 (17.5%)] - Loss = 2.5244
Epoch 10 - Valid [150/573 (26.2%)] - Loss = 2.5264
Epoch 10 - Valid [200/573 (34.9%)] - Loss = 2.5142
Epoch 10 - Valid [250/573 (43.6%)] - Loss = 2.5398
Epoch 10 - Valid [300/573 (52.4%)] - Loss = 2.5564
Epoch 10 - Valid [350/573 (61.1%)] - Loss = 2.5467
Epoch 10 - Valid [400/573 (69.8%)] - Loss = 2.5473
Epoch 10 - Valid [450/573 (78.5%)] - Loss = 2.5441
Epoch 10 - Valid [500/573 (87.3%)] - Loss = 2.5398
Epoch 10 - Valid [550/573 (96.0%)] - Loss = 2.5341
Epoch 10 - Valid [573/573 (100.0%)] - Loss = 2.5340
Epoch 10 - Valid - Avg AUC = 0.6406
Done
